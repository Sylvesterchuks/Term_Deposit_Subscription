## XGBOOST
XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. 

XGBoost Features
The library is more focused on computational speed and model performance, it does offer a number of advanced features.

#### Model Features
* Gradient Boosting algorithm also called gradient boosting machine including the learning rate.
* Stochastic Gradient Boosting with sub-sampling at the row, column and column per split levels.
* Regularized Gradient Boosting with both L1 and L2 regularization.
#### System Features
Parallelization of tree construction using all of your CPU cores during training.
Distributed Computing for training very large models using a cluster of machines.
Cache Optimization of data structures and algorithm to make best use of hardware.

#### Algorithm Features
Automatic handling of missing data values.
XGBoost is free open source software.

Why Use XGBoost?
The two reasons to use XGBoost are also the two goals of the project:
* Execution Speed.
* Model Performance.
1. XGBoost Execution Speed
XGBoost is fast. Really fast when compared to other implementations of gradient boosting.
2. XGBoost Model Performance
XGBoost dominates structured or tabular datasets on classification and regression predictive modeling problems.

#### Reference:
click here: https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/
